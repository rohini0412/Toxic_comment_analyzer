{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7913971,
          "sourceType": "datasetVersion",
          "datasetId": 4649756
        },
        {
          "sourceId": 7914187,
          "sourceType": "datasetVersion",
          "datasetId": 4649920
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text\n",
        "\n",
        "It does not require GPU access to run this notebook.\n",
        "\n",
        "This notebook is authored by [Anmol Talwar](https://www.linkedin.com/in/anmol-talwar-922061164/) - Founder and Trainer at Talent Catalyst AI\n",
        "\n",
        "Visit the blogs on [Talent Catalyst AI](https://talentcatalystai.com/) to learn more on New Gen Technology"
      ],
      "metadata": {
        "id": "Btk5iyxP7kMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SpeechRecognition**\n",
        "\n",
        "Speech recognition is the ability of computer software to identify words and phrases in spoken language and convert them to human-readable text. We will use [SpeechRecognition library](https://pypi.org/project/SpeechRecognition/) for our task.\n",
        "\n",
        "Using this library, we do not need to build any ML model as library provides us with convenient wrappers for various well-known public speech recognition APIs such as  :\n",
        "\n",
        "* CMU Sphinx (works offline)\n",
        "* **Google Speech Recognition**\n",
        "* Google Cloud Speech API\n",
        "* Wit.ai\n",
        "* Microsoft Azure Speech\n",
        "* Microsoft Bing Voice Recognition (Deprecated)\n",
        "* Houndify API\n",
        "* IBM Speech to Text\n",
        "* Snowboy Hotword Detection (works offline)\n",
        "* Tensorflow\n",
        "* Vosk API (works offline)\n",
        "* OpenAI whisper (works offline)\n",
        "* Whisper API"
      ],
      "metadata": {
        "id": "NSisfZC-7kMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#intstalling the dependancies\n",
        "!pip install SpeechRecognition pydub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:04.797666Z",
          "iopub.execute_input": "2024-03-29T09:56:04.798435Z",
          "iopub.status.idle": "2024-03-29T09:56:21.862836Z",
          "shell.execute_reply.started": "2024-03-29T09:56:04.798359Z",
          "shell.execute_reply": "2024-03-29T09:56:21.861669Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnSc3qtP7kMm",
        "outputId": "f6678a8f-296e-430f-899f-70164765f537"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.6.2)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.4 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required packages\n",
        "import speech_recognition as sr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:21.865510Z",
          "iopub.execute_input": "2024-03-29T09:56:21.865955Z",
          "iopub.status.idle": "2024-03-29T09:56:21.968119Z",
          "shell.execute_reply.started": "2024-03-29T09:56:21.865907Z",
          "shell.execute_reply": "2024-03-29T09:56:21.966999Z"
        },
        "trusted": true,
        "id": "INBo3e3k7kMp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio File Path\n",
        "filename = \"/content/machine-learning_speech-recognition_16-122828-0002.wav\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:21.969959Z",
          "iopub.execute_input": "2024-03-29T09:56:21.970641Z",
          "iopub.status.idle": "2024-03-29T09:56:21.975210Z",
          "shell.execute_reply.started": "2024-03-29T09:56:21.970607Z",
          "shell.execute_reply": "2024-03-29T09:56:21.974148Z"
        },
        "trusted": true,
        "id": "mlHx5kGY7kMq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the recognizer\n",
        "r = sr.Recognizer()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:21.977464Z",
          "iopub.execute_input": "2024-03-29T09:56:21.977834Z",
          "iopub.status.idle": "2024-03-29T09:56:21.988303Z",
          "shell.execute_reply.started": "2024-03-29T09:56:21.977804Z",
          "shell.execute_reply": "2024-03-29T09:56:21.987105Z"
        },
        "trusted": true,
        "id": "y_iXNPJ27kMq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file\n",
        "with sr.AudioFile(filename) as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:21.990896Z",
          "iopub.execute_input": "2024-03-29T09:56:21.991246Z",
          "iopub.status.idle": "2024-03-29T09:56:22.775741Z",
          "shell.execute_reply.started": "2024-03-29T09:56:21.991217Z",
          "shell.execute_reply": "2024-03-29T09:56:22.774603Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0a3lMf57kMq",
        "outputId": "f5e4ac71-ff6d-4560-86c8-501df2176619"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I believe you are just talking nonsense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transcribing Large Audio Files**"
      ],
      "metadata": {
        "id": "VM9PY4aO7kMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function uses split_on_silence() function from pydub.silence module to split audio data into chunks on silence. The min_silence_len parameter is the minimum length of silence in milliseconds to be used for a split.\n",
        "\n",
        "silence_thresh is the threshold in which anything quieter than this will be considered silence, I have set it to the average dBFS minus 14, keep_silence argument is the amount of silence to leave at the beginning and the end of each chunk detected in milliseconds."
      ],
      "metadata": {
        "id": "6u0yj3l-7kMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:22.777615Z",
          "iopub.execute_input": "2024-03-29T09:56:22.778473Z",
          "iopub.status.idle": "2024-03-29T09:56:22.793809Z",
          "shell.execute_reply.started": "2024-03-29T09:56:22.778432Z",
          "shell.execute_reply": "2024-03-29T09:56:22.792734Z"
        },
        "trusted": true,
        "id": "Gqldbqri7kMs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a speech recognition object\n",
        "r = sr.Recognizer()\n",
        "\n",
        "# a function to recognize speech in the audio file\n",
        "# so that we don't repeat ourselves in in other functions\n",
        "def transcribe_audio(path):\n",
        "    # use the audio file as the audio source\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "        # try converting it to text\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:22.795274Z",
          "iopub.execute_input": "2024-03-29T09:56:22.795990Z",
          "iopub.status.idle": "2024-03-29T09:56:22.802620Z",
          "shell.execute_reply.started": "2024-03-29T09:56:22.795951Z",
          "shell.execute_reply": "2024-03-29T09:56:22.801379Z"
        },
        "trusted": true,
        "id": "-LDn59Yn7kMs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function that splits the audio file into chunks on silence\n",
        "# and applies speech recognition\n",
        "def get_large_audio_transcription_on_silence(path):\n",
        "    \"\"\"Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
        "    chunks = split_on_silence(sound,\n",
        "        # experiment with this value for your target audio file\n",
        "        min_silence_len = 500,\n",
        "        # adjust this per requirement\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "        # keep the silence for 1 second, adjustable as well\n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:22.804129Z",
          "iopub.execute_input": "2024-03-29T09:56:22.804641Z",
          "iopub.status.idle": "2024-03-29T09:56:22.815853Z",
          "shell.execute_reply.started": "2024-03-29T09:56:22.804603Z",
          "shell.execute_reply": "2024-03-29T09:56:22.814790Z"
        },
        "trusted": true,
        "id": "peCoMHhh7kMt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/machine-learning_speech-recognition_7601-291468-0006.wav\"\n",
        "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T09:56:22.817125Z",
          "iopub.execute_input": "2024-03-29T09:56:22.817726Z",
          "iopub.status.idle": "2024-03-29T09:56:32.035174Z",
          "shell.execute_reply.started": "2024-03-29T09:56:22.817683Z",
          "shell.execute_reply": "2024-03-29T09:56:32.033883Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZvHtC-37kMt",
        "outputId": "8470ceea-4d4c-45b1-81b4-8da75c97dcce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Here's a bird which he had fixed in a bowery or a country seat. \n",
            "audio-chunks/chunk2.wav : Add a short distance from the city. \n",
            "audio-chunks/chunk3.wav : Just that what is now called dutch street. \n",
            "audio-chunks/chunk4.wav : Soon abounded with proofs of his ingenuity. \n",
            "audio-chunks/chunk5.wav : Patent smoke. \n",
            "audio-chunks/chunk6.wav : It required a horse to work some. \n",
            "audio-chunks/chunk7.wav : Dutch ovens that roasted meat without fire. \n",
            "audio-chunks/chunk8.wav : Carts that went before the horses. \n",
            "audio-chunks/chunk9.wav : Weather cox that turned against the wind and other wrong-headed contrivances. \n",
            "audio-chunks/chunk10.wav : Set astonished and confounded all beholders. \n",
            "\n",
            "Full text: Here's a bird which he had fixed in a bowery or a country seat. Add a short distance from the city. Just that what is now called dutch street. Soon abounded with proofs of his ingenuity. Patent smoke. It required a horse to work some. Dutch ovens that roasted meat without fire. Carts that went before the horses. Weather cox that turned against the wind and other wrong-headed contrivances. Set astonished and confounded all beholders. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQpiOc8M-KLI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}